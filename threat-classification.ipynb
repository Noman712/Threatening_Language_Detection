{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install keras==2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import cross_validate    \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score,fbeta_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras import backend\n",
    "from keras import backend as K\n",
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM, Dropout, Flatten, Embedding, Bidirectional, GlobalAveragePooling1D\n",
    "from keras.layers import Conv1D,Conv2D, MaxPooling2D, MaxPooling1D, GlobalMaxPooling1D\n",
    "\n",
    "from keras.optimizers import SGD,RMSprop,Adam,Adadelta,Adagrad,Adamax\n",
    "from keras.regularizers import l2,l1\n",
    "\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv1D,Conv2D, MaxPooling2D, MaxPooling1D\n",
    "\n",
    "\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG\n",
    "\n",
    "\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, PorterStemmer ,WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.wrappers import FastText\n",
    "from gensim.models.fasttext import FastText, load_facebook_vectors\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#global random seed code to check it is working\n",
    "#when you set the random seed at start it works like a global variable...\n",
    "#you do not need to specify random seed in sklearn\n",
    "\n",
    "\n",
    "_seed = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "def reset_seeds(reset_graph_with_backend=None):\n",
    "    if reset_graph_with_backend is not None:\n",
    "        K = reset_graph_with_backend\n",
    "        K.clear_session()\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        print(\"KERAS AND TENSORFLOW GRAPHS RESET\")  # optional\n",
    "\n",
    "    np.random.seed(_seed)\n",
    "    random.seed(_seed)\n",
    "    tf.compat.v1.set_random_seed(_seed)\n",
    "    print(\"RANDOM SEEDS RESET\")  # optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reset_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(_seed) #set random seed to produce same results\n",
    "print(norm.rvs(10, size = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print('Without seed')\n",
    "print(norm.rvs(10, size = 4))\n",
    "print(norm.rvs(10, size = 4))\n",
    "\n",
    "print('With the same seed')\n",
    "np.random.seed(_seed) \n",
    "print(norm.rvs(10, size = 4))\n",
    "np.random.seed(_seed) # reset the random seed back to 31415\n",
    "print(norm.rvs(10, size = 4))\n",
    "\n",
    "print('Without seed')\n",
    "np.random.seed(None)\n",
    "print(norm.rvs(10, size = 4))\n",
    "print(norm.rvs(10, size = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from urduhack import normalize\n",
    "from urduhack.preprocess import normalize_whitespace\n",
    "from urduhack.normalization import normalize_characters\n",
    "from urduhack.normalization import digits_space\n",
    "from urduhack.normalization import punctuations_space\n",
    "from urduhack.normalization import remove_diacritics\n",
    "from urduhack.preprocess import remove_accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def RemoveEmoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                       u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                       u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                       u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                       u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                       u\"\\U00002702-\\U000027B0\"\n",
    "                       u\"\\U000024C2-\\U0001F251\"\n",
    "                       \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)    \n",
    "\n",
    "\n",
    "def Normalize_Urdu(text):\n",
    "    normalized_text = normalize_whitespace(text)\n",
    "    normalized_text = normalize_characters(normalized_text)\n",
    "    normalized_text =  normalize(normalized_text)\n",
    "    normalized_text = punctuations_space(normalized_text)\n",
    "    normalized_text = remove_accents(normalized_text)\n",
    "    return normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = \"dataset.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xl1 = pd.ExcelFile(dataset)\n",
    "xl1.sheet_names\n",
    "\n",
    "df = xl1.parse(\"Sheet1\")\n",
    "df = df.drop_duplicates(keep=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>label</th>\n",
       "      <th>S/G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>بکواس مت کرو</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>تمہاری ہیجڑا فورس ایک نہتے کے سامنے بکری بنی ہ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>آفیسر سمیتبھارتی فوجی جہنم واصل،بنکرز تباہ بھا...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>غدار منافق میر اللہ تمہیں زلیل کرے</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>اگست پر آپ بھارت کو کیا پیغام دینا چاہیں گے؟ م...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  label  S/G\n",
       "0                                       بکواس مت کرو      1    1\n",
       "1  تمہاری ہیجڑا فورس ایک نہتے کے سامنے بکری بنی ہ...      1    0\n",
       "2  آفیسر سمیتبھارتی فوجی جہنم واصل،بنکرز تباہ بھا...      1    1\n",
       "3                 غدار منافق میر اللہ تمہیں زلیل کرے      1    1\n",
       "4  اگست پر آپ بھارت کو کیا پیغام دینا چاہیں گے؟ م...      1    0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Tweets']=df['Tweets'].apply(Normalize_Urdu)\n",
    "df['Tweets']=df['Tweets'].apply(RemoveEmoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n",
      "3564\n"
     ]
    }
   ],
   "source": [
    "yTrain = df.label.values\n",
    "print(yTrain)\n",
    "print(len(yTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ngram_range = (1,1)\n",
    "_max_features = 50\n",
    "_analyzer = 'word' #'char' #word/char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train data load\n",
    "train_text = []\n",
    "count = 0\n",
    "for index,row in df.iterrows():\n",
    "    text = str(row['Tweets'])\n",
    "    train_text.append(text)\n",
    "    count = count + 1\n",
    "\n",
    "print(train_text[0])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 10)\t1.0\n",
      "Shape of final Ngram vector:(1782, 50)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfIdfVectorizer=TfidfVectorizer(smooth_idf=True,use_idf=True, ngram_range= _ngram_range, analyzer = _analyzer, max_features=_max_features)\n",
    "X_train = tfIdfVectorizer.fit_transform(train_text)\n",
    "print(X_train[0])\n",
    "print( \"Shape of final Ngram vector:\" + str(X_train.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xTrain, yTrain = X_train, yTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1782, 50)\n",
      "(3564,)\n"
     ]
    }
   ],
   "source": [
    "print(xTrain.shape)\n",
    "print(yTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scorer = make_scorer(f1_score, average = 'weighted')\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "def LR_Model(X, y):\n",
    "    clf = LogisticRegression(random_state=_seed)\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=False, random_state=_seed)\n",
    "    cfmean = []\n",
    "    accmean = []\n",
    "    precmean = []\n",
    "    recmean = []\n",
    "    f1mean = []\n",
    "\n",
    "    \n",
    "    count = 1\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X, y)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"Iteration:\" + str(count))\n",
    "        \n",
    "        print(\"=== Scores ===\")\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print('Accuracy: %f' % accuracy)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        print('Precision: %f' % precision)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        print('Recall: %f' % recall)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        print('F1 score: %f' % f1)\n",
    "        \n",
    "        accmean.append(accuracy)\n",
    "        precmean.append(precision)\n",
    "        recmean.append(recall)\n",
    "        f1mean.append(f1)\n",
    "        \n",
    "        \n",
    "        print(\"=== Confusion Matrix ===\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        cfmean.append(confusion_matrix(y_test, y_pred))\n",
    "  \n",
    "        print('\\n')\n",
    "        count = count + 1\n",
    "        \n",
    "\n",
    "    \n",
    "    acc = np.mean(accmean, axis=0)\n",
    "    pre = np.mean(precmean, axis=0)\n",
    "    cm = np.mean(cfmean, axis=0)\n",
    "    re = np.mean(recmean, axis=0)\n",
    "    f1 = np.mean(f1mean, axis=0)\n",
    "    \n",
    "    print('\\n')\n",
    "    print(\"Averages\")\n",
    "    print(\"Accuracy: \" + str(acc))\n",
    "    print(\"Precision: \" + str(pre))\n",
    "    print(\"Recall: \" + str(re))\n",
    "    print(\"F1 measure: \" + str(f1))\n",
    "    print('Confusion Matrix\\n')\n",
    "    print(cm)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    return clf, kfold\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr, cv = LR_Model(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def MLP_Model(X, y):\n",
    "    clf = MLPClassifier(random_state=_seed)\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=False, random_state=_seed)\n",
    "    cfmean = []\n",
    "    accmean = []\n",
    "    precmean = []\n",
    "    recmean = []\n",
    "    f1mean = []\n",
    "\n",
    "    \n",
    "    count = 1\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X, y)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"Iteration:\" + str(count))\n",
    "        \n",
    "        print(\"=== Scores ===\")\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print('Accuracy: %f' % accuracy)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        print('Precision: %f' % precision)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        print('Recall: %f' % recall)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        print('F1 score: %f' % f1)\n",
    "        \n",
    "        accmean.append(accuracy)\n",
    "        precmean.append(precision)\n",
    "        recmean.append(recall)\n",
    "        f1mean.append(f1)\n",
    "        \n",
    "        \n",
    "        print(\"=== Confusion Matrix ===\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        cfmean.append(confusion_matrix(y_test, y_pred))\n",
    "  \n",
    "        print('\\n')\n",
    "        count = count + 1\n",
    "        \n",
    "\n",
    "    \n",
    "    acc = np.mean(accmean, axis=0)\n",
    "    pre = np.mean(precmean, axis=0)\n",
    "    cm = np.mean(cfmean, axis=0)\n",
    "    re = np.mean(recmean, axis=0)\n",
    "    f1 = np.mean(f1mean, axis=0)\n",
    "    \n",
    "    print('\\n')\n",
    "    print(\"Averages\")\n",
    "    print(\"Accuracy: \" + str(acc))\n",
    "    print(\"Precision: \" + str(pre))\n",
    "    print(\"Recall: \" + str(re))\n",
    "    print(\"F1 measure: \" + str(f1))\n",
    "    print('Confusion Matrix\\n')\n",
    "    print(cm)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    return clf, kfold\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mlp, cv = MLP_Model(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def AB_Model(X, y):\n",
    "    clf = AdaBoostClassifier(random_state=_seed)\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=False, random_state=_seed)\n",
    "    cfmean = []\n",
    "    accmean = []\n",
    "    precmean = []\n",
    "    recmean = []\n",
    "    f1mean = []\n",
    "\n",
    "    \n",
    "    count = 1\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X, y)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"Iteration:\" + str(count))\n",
    "        \n",
    "        print(\"=== Scores ===\")\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print('Accuracy: %f' % accuracy)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        print('Precision: %f' % precision)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        print('Recall: %f' % recall)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        print('F1 score: %f' % f1)\n",
    "        \n",
    "        accmean.append(accuracy)\n",
    "        precmean.append(precision)\n",
    "        recmean.append(recall)\n",
    "        f1mean.append(f1)\n",
    "\n",
    "        \n",
    "        print(\"=== Confusion Matrix ===\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        cfmean.append(confusion_matrix(y_test, y_pred))\n",
    "  \n",
    "        print('\\n')\n",
    "        count = count + 1\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    acc = np.mean(accmean, axis=0)\n",
    "    pre = np.mean(precmean, axis=0)\n",
    "    cm = np.mean(cfmean, axis=0)\n",
    "    re = np.mean(recmean, axis=0)\n",
    "    f1 = np.mean(f1mean, axis=0)\n",
    "    \n",
    "    print('\\n')\n",
    "    print(\"Averages\")\n",
    "    print(\"Accuracy: \" + str(acc))\n",
    "    print(\"Precision: \" + str(pre))\n",
    "    print(\"Recall: \" + str(re))\n",
    "    print(\"F1 measure: \" + str(f1))\n",
    "    print('Confusion Matrix\\n')\n",
    "    print(cm)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    return clf, kfold\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adb, cv  = AB_Model(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " def RF_Model(X, y,algoname= ' '):\n",
    "    clf = RandomForestClassifier(random_state=_seed)\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=False, random_state=_seed)\n",
    "    cfmean = []\n",
    "    accmean = []\n",
    "    precmean = []\n",
    "    recmean = []\n",
    "    f1mean = []\n",
    "    \n",
    "    count = 1\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X, y)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"Iteration:\" + str(count))\n",
    "        \n",
    "        print(\"=== Scores ===\")\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print('Accuracy: %f' % accuracy)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        print('Precision: %f' % precision)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        print('Recall: %f' % recall)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        print('F1 score: %f' % f1)\n",
    "        \n",
    "        accmean.append(accuracy)\n",
    "        precmean.append(precision)\n",
    "        recmean.append(recall)\n",
    "        f1mean.append(f1)\n",
    "        \n",
    "        \n",
    "        print(\"=== Confusion Matrix ===\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        cfmean.append(confusion_matrix(y_test, y_pred))\n",
    "  \n",
    "        print('\\n')\n",
    "        count = count + 1\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    acc = np.mean(accmean, axis=0)\n",
    "    pre = np.mean(precmean, axis=0)\n",
    "    cm = np.mean(cfmean, axis=0)\n",
    "    re = np.mean(recmean, axis=0)\n",
    "    f1 = np.mean(f1mean, axis=0)\n",
    "    \n",
    "    print('\\n')\n",
    "    print(\"Averages\")\n",
    "    print(\"Accuracy: \" + str(acc))\n",
    "    print(\"Precision: \" + str(pre))\n",
    "    print(\"Recall: \" + str(re))\n",
    "    print(\"F1 measure: \" + str(f1))\n",
    "    print('Confusion Matrix\\n')\n",
    "    print(cm)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    return clf, kfold\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf, cv = RF_Model(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "def SVM_Model(X, y):\n",
    "    clf = SVC(probability=True,class_weight='balanced', random_state=_seed)\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=False, random_state=_seed)\n",
    "    cfmean = []\n",
    "    accmean = []\n",
    "    precmean = []\n",
    "    recmean = []\n",
    "    f1mean = []\n",
    "    \n",
    "    count = 1\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X, y)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"Iteration:\" + str(count))\n",
    "        \n",
    "        print(\"=== Scores ===\")\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print('Accuracy: %f' % accuracy)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        print('Precision: %f' % precision)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        print('Recall: %f' % recall)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        print('F1 score: %f' % f1)\n",
    "        \n",
    "        accmean.append(accuracy)\n",
    "        precmean.append(precision)\n",
    "        recmean.append(recall)\n",
    "        f1mean.append(f1)\n",
    "        \n",
    "\n",
    "        \n",
    "        print(\"=== Confusion Matrix ===\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        cfmean.append(confusion_matrix(y_test, y_pred))\n",
    "  \n",
    "        print('\\n')\n",
    "        count = count + 1\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    acc = np.mean(accmean, axis=0)\n",
    "    pre = np.mean(precmean, axis=0)\n",
    "    cm = np.mean(cfmean, axis=0)\n",
    "    re = np.mean(recmean, axis=0)\n",
    "    f1 = np.mean(f1mean, axis=0)\n",
    "    \n",
    "    print('\\n')\n",
    "    print(\"Averages\")\n",
    "    print(\"Accuracy: \" + str(acc))\n",
    "    print(\"Precision: \" + str(pre))\n",
    "    print(\"Recall: \" + str(re))\n",
    "    print(\"F1 measure: \" + str(f1))\n",
    "    print('Confusion Matrix\\n')\n",
    "    print(cm)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    return clf, kfold\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm,cv = SVM_Model(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
